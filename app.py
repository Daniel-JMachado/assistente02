"""
TARS - Assistente de IA para An√°lise de Conte√∫do

Este √© o ponto de entrada principal da aplica√ß√£o TARS, que fornece
uma interface de chat com o modelo de IA Claude para an√°lise de conte√∫do
de diferentes fontes (sites, v√≠deos, PDFs, etc).

Desenvolvido para estudantes universir√°rio
"""

import streamlit as st
from config.settings import APP_NAME, APP_ICON
from core.session import initialize_session, clear_conversation, add_message
from core.llm import generate_response
from ui.components import (
    load_css, header, chat_message, sidebar_header, 
    source_selector, source_info_panel, clear_conversation_button,
    timestamp_display, footer
)
from ui.pages.sources import render_source_interface

# Configura√ß√£o da p√°gina Streamlit
st.set_page_config(
    page_title=APP_NAME,
    page_icon=APP_ICON,
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={}  # Remove itens do menu
)

# Carrega os estilos CSS personalizados
load_css()

# Inicializa o estado da sess√£o
initialize_session()

# Exibe o cabe√ßalho principal
header()

# Cabe√ßalho da barra lateral
sidebar_header()

# Seletor de fonte de dados
fonte = source_selector()

# Renderiza interface para a fonte selecionada
render_source_interface(fonte)

# Bot√£o para limpar a conversa
if clear_conversation_button():
    clear_conversation()
    st.rerun()

# Exibe timestamp na barra lateral
timestamp_display()

# Se uma fonte de dados foi carregada, exibe informa√ß√µes
if st.session_state.documento:
    # Exibe informa√ß√µes sobre a fonte atual
    source_info_panel(st.session_state.documento)

# Separador visual entre informa√ß√µes da fonte e o chat
st.markdown("---")

# Exibe o hist√≥rico de mensagens
for mensagem in st.session_state.mensagens:
    avatar = "üë§" if mensagem["role"] == "user" else "ü§ñ"
    chat_message(mensagem["role"], mensagem["content"], avatar)

# Campo de entrada de texto para o usu√°rio
prompt = st.chat_input("Digite sua pergunta...", key="chat_input")

# Processa a entrada do usu√°rio
if prompt:
    # Adiciona a mensagem do usu√°rio ao hist√≥rico e exibe
    add_message("user", prompt)
    chat_message("user", prompt, "üë§")
    
    # Obt√©m resposta do modelo com o contexto atual
    with st.spinner("TARS est√° processando sua pergunta..."):
        try:
            # Gera a resposta do modelo
            resposta = generate_response(st.session_state.mensagens, st.session_state.documento)
            
            # Exibe a resposta
            chat_message("assistant", resposta, "ü§ñ")
            
            # Adiciona a resposta ao hist√≥rico
            add_message("assistant", resposta)
        except Exception as e:
            error_msg = f"Desculpe, ocorreu um erro ao processar sua pergunta: {str(e)}"
            st.error(error_msg)
            chat_message("assistant", error_msg, "ü§ñ")
            add_message("assistant", error_msg)

# Exibe o rodap√©
footer()

# Exibe uma mensagem de boas-vindas se for a primeira execu√ß√£o da sess√£o
if not st.session_state.mensagens:
    st.info(
        """üëã Bem-vindo ao TARS! Selecione uma fonte de dados na barra lateral para come√ßar. 
        Voc√™ pode carregar sites, v√≠deos do YouTube, documentos PDF ou simplesmente iniciar um chat livre."""
    )